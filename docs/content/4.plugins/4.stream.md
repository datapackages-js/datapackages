---
title: Stream Plugin
description: Efficiently process large datasets using streams and NDJSON support.
---

# Stream

The `@datapackages/plugin-stream` middleware enables processing of large datasets using Node.js streams, including NDJSON support.

## Interaction Flow

::mermaid
<pre>
sequenceDiagram
    participant DS as Dataset
    participant Plugin as withStream
    participant Source as HTTP (NDJSON)

    DS->>Plugin: load() [intercepted]
    Plugin->>Source: fetch(url)
    Source-->>Plugin: ReadableStream
    Plugin->>DS: return AsyncIterable
    
    loop For each chunk
        Source->>Plugin: Data chunk
        Plugin->>DS: yield TItem
        DS->>DS: push to _dataStack
    end
    
    Note over DS: init() resolves
</pre>
::

## Installation

```bash
npm install @datapackages/plugin-stream
```

## Usage

```typescript
import { withStream } from "@datapackages/plugin-stream";

// Configure dataset to use streaming
await dataset.use(withStream());

// Initialize to start the stream
await dataset.init();

// Items are accessible via getAll() after init, 
// or you can process them as they load using hooks.
```

## Middleware Ordering

When combining with `@datapackages/plugin-cache`, ensure `withStream()` is applied **before** `withCache()` so that items can be yielded and then cached.

```typescript
await dataset
  .use(withStream())
  .use(withCache());
```


## NDJSON Support

The plugin automatically detects `.ndjson` files and uses a specialized parser to stream records efficiently without loading the entire file into memory.

## Features

- **Memory Efficient**: Ideal for processing huge datasets.
- **Universal**: Works with standard web streams and Node.js streams.
- **NDJSON**: Native support for Newline Delimited JSON.
